{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oKFmvGZ_enNU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from monai.utils import first, set_determinism, progress_bar\n",
    "import SimpleITK as sitk  # noqa: N813\n",
    "import numpy as np\n",
    "import itk\n",
    "import tempfile\n",
    "import monai\n",
    "from monai.data import PILReader\n",
    "from monai.transforms import (LoadImage, LoadImaged,ScaleIntensityRangePercentiles, Resized, Compose, SaveImage, \n",
    "ScaleIntensity,RandScaleIntensity, SpatialPadd)\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, NiftiSaver\n",
    "import glob\n",
    "import torch\n",
    "import nibabel as nib\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    NormalizeIntensityd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    RandAffined,\n",
    "    SpatialPadd,\n",
    "    Rand3DElasticd,\n",
    "    RandFlipd,\n",
    "    ResizeWithPadOrCropd\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch, PatchDataset\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "from monai.inferers import sliding_window_inference\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/athurai3\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    dropout = 0.4,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 650/650 [05:33<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "test_ct = ['projects/ctb-akhanf/athurai3/unet_contact_seg/sample_data/sub-P003/sub-P003_desc-rigid_space-T1w_znorm_ct.nii.gz']\n",
    "\n",
    "test_data = [{\"image\": image} for image in test_ct]\n",
    "\n",
    "test_transforms = Compose( #loading full image\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"])])\n",
    "\n",
    "test_ds = Dataset(data = test_data, transform = test_transforms)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size = 1, num_workers = 1)\n",
    "\n",
    "\n",
    "post_transforms = post_transforms = Compose(\n",
    "    [\n",
    "        Activations(sigmoid = True),\n",
    "        AsDiscrete(threshold = 0.5),\n",
    "        #SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=monai_test_dir, resample=False),\n",
    "    ]\n",
    ")\n",
    "post_pred = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "date = 'Feb16'\n",
    "pred_imgs = []\n",
    "model.load_state_dict(torch.load(f'/home/athurai3/scratch/monai_outputs/UNET/{date}/checkpoint.pt', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for test_img in test_loader:\n",
    "        test_inputs = test_img['image'].to('cpu')\n",
    "        roi_size = (32, 32, 32)\n",
    "        sw_batch_size = 5\n",
    "        pred_img = sliding_window_inference(inputs = test_inputs, roi_size=roi_size, sw_batch_size = sw_batch_size, predictor = model.to('cpu'),\n",
    "                                            overlap = 0.15, mode = 'constant', sw_device = 'cpu', device = 'cpu', progress=True)\n",
    "        pred_imgs.append(pred_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_imgs = post_transforms(pred_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpred_imgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "pred_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = pred_imgs[0][0][0]\n",
    "file_name_pred = 'scratch/sub-P003_desc-rigid_space-T1w_ct_pred.nii.gz'\n",
    "orig_test = nib.load('projects/ctb-akhanf/athurai3/unet_contact_seg/sample_data/sub-P003/sub-P003_desc-rigid_space-T1w_znorm_ct.nii.gz')\n",
    "file = nib.Nifti1Image(prediction.detach().numpy(), affine = orig_test.affine, header = orig_test.header)\n",
    "nib.save(file, file_name_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-P100',\n",
       " 'sub-P104',\n",
       " 'sub-P105',\n",
       " 'sub-P106',\n",
       " 'sub-P107',\n",
       " 'sub-P109',\n",
       " 'sub-P110',\n",
       " 'sub-P111',\n",
       " 'sub-P112',\n",
       " 'sub-P113',\n",
       " 'sub-P114']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_dir = '/scratch/athurai3/preproc_outputs/test_data'\n",
    "subjects = [identifier for identifier in os.listdir(test_dir) if \"sub-\" in identifier]\n",
    "subjects = sorted(subjects)\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
