{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oKFmvGZ_enNU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from monai.utils import first, set_determinism, progress_bar\n",
    "import SimpleITK as sitk  # noqa: N813\n",
    "import numpy as np\n",
    "import itk\n",
    "import tempfile\n",
    "import monai\n",
    "from monai.data import PILReader\n",
    "from monai.transforms import (LoadImage, LoadImaged,ScaleIntensityRangePercentiles, Resized, Compose, SaveImage, \n",
    "ScaleIntensity,RandScaleIntensity, SpatialPadd)\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, NiftiSaver\n",
    "import glob\n",
    "import torch\n",
    "import nibabel as nib\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    NormalizeIntensityd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    RandAffined,\n",
    "    SpatialPadd,\n",
    "    Rand3DElasticd,\n",
    "    RandFlipd,\n",
    "    ResizeWithPadOrCropd\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch, PatchDataset\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "from monai.inferers import sliding_window_inference\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/athurai3\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    dropout = 0.4,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 650/650 [05:57<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "test_ct = ['projects/ctb-akhanf/athurai3/unet_contact_seg/sample_data/sub-P003/sub-P003_desc-rigid_space-T1w_znorm_ct.nii.gz']\n",
    "\n",
    "test_data = [{\"image\": image} for image in test_ct]\n",
    "\n",
    "test_transforms = Compose( #loading full image\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"])])\n",
    "\n",
    "test_ds = Dataset(data = test_data, transform = test_transforms)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size = 1, num_workers = 1)\n",
    "\n",
    "\n",
    "post_transforms = post_transforms = Compose(\n",
    "    [\n",
    "        Activations(sigmoid = True),\n",
    "        AsDiscrete(threshold = 0.5),\n",
    "        #SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=monai_test_dir, resample=False),\n",
    "    ]\n",
    ")\n",
    "post_pred = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "date = '2024Feb5'\n",
    "pred_imgs = []\n",
    "model.load_state_dict(torch.load(f'/home/athurai3/scratch/seeg_contacts_loc/derivatives/UNET/{date}_diceloss_checkpoint.pt', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for test_img in test_loader:\n",
    "        test_inputs = test_img['image'].to('cpu')\n",
    "        roi_size = (32, 32, 32)\n",
    "        sw_batch_size = 5\n",
    "        pred_img = sliding_window_inference(inputs = test_inputs, roi_size=roi_size, sw_batch_size = sw_batch_size, predictor = model.to('cpu'),\n",
    "                                            overlap = 0.15, mode = 'constant', sw_device = 'cpu', device = 'cpu', progress=True)\n",
    "        pred_imgs.append(pred_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_imgs = post_transforms(pred_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(pred_imgs[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = pred_imgs[0][0][0]\n",
    "file_name_pred = 'scratch/sub-P003_desc-rigid_space-T1w_ct_pred.nii.gz'\n",
    "orig_test = nib.load('projects/ctb-akhanf/athurai3/unet_contact_seg/sample_data/sub-P003/sub-P003_desc-rigid_space-T1w_znorm_ct.nii.gz')\n",
    "file = nib.Nifti1Image(prediction.detach().numpy(), affine = orig_test.affine, header = orig_test.header)\n",
    "nib.save(file, file_name_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname = 'projects/ctb-akhanf/athurai3/unet_contact_seg/sample_data/sub-P001/sub-P001_desc-clipped_patches.dat'\n",
    "bps = 4 * num_channels * np.prod(dims)         # Bytes per sample\n",
    "file_size = os.path.getsize(fname) \n",
    "num_samples = np.floor_divide(file_size,bps)   # Number of samples\n",
    "print(file_size)\n",
    "print(bps)\n",
    "print(num_samples)\n",
    "\n",
    "\n",
    "#can change first index from num_samples to try with training on smaller number of jobs, kjupyter job\n",
    "dims = dims.astype('int')\n",
    "arr_shape_train = (num_samples, dims[0],dims[1],dims[2],num_channels)\n",
    "\n",
    "arr_train = np.memmap(fname,'float32','r',shape=arr_shape_train)\n",
    "#arr_train = np.swapaxes(arr_train,1,3)\n",
    "print(arr_shape_train)\n",
    "\n",
    "arr_train = np.swapaxes(arr_train,1,4)\n",
    "arr_train_image = arr_train[:,0,:,:,:].reshape(arr_train.shape[0],1,arr_train.shape[2],arr_train.shape[3],arr_train.shape[4])\n",
    "arr_train_label = arr_train[:,1,:,:,:].reshape(arr_train.shape[0],1,arr_train.shape[2],arr_train.shape[3],arr_train.shape[4])\n",
    "\n",
    "thresh_train_label = np.where(arr_train_label[:][:] > 0, 1, arr_train_label)\n",
    "\n",
    "arr_train_dict= [{\"image\": ct, \"label\": contact} for ct, contact in zip(arr_train_image,thresh_train_label)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
